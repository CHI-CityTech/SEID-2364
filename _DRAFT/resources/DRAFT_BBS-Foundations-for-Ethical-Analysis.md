# [DRAFT] BBS Foundations for Ethical Analysis: Quick Guide

**Status:** Under consideration as foundational bridge material  
**Intended Use:** Week 1–2 reading; reference throughout course  
**Purpose:** Simplify BBS concepts and ground them in ethical reasoning

---

## What is Balanced Blended Space (BBS)?

BBS is a **relational framework**—a way of thinking about how different kinds of intelligence (human, computational, institutional) live together in shared spaces and interact through mediation.

In a nutshell: **BBS asks: "Who decides? How do they decide? What information shapes their choices? Who doesn't get heard?"**

This makes BBS perfect for ethical analysis, because ethics is fundamentally about *responsibility* and *agency in relation to others*.

---

## The Core BBS Model: Seven Elements

### 1. **Agents**

**Definition:** Any entity with capacity to influence outcomes.

**Types of agents in ethical contexts:**
- **Human agents:** Individuals, communities, stakeholders affected by decisions
- **Computational agents:** Algorithms, AI systems, automated processes
- **Institutional agents:** Organizations, governments, corporations
- **Conceptual agents:** Cultural heritage, values, future generations

**Ethical question:** Which agents have voice and power? Which are silent or disempowered?

**Example:** In Quantum Musico, agents include Mozart (historical), the algorithm, contemporary composers, cultural communities, audiences, Meta (institutional).

---

### 2. **Agency**

**Definition:** The capacity to act autonomously and shape outcomes.

**Agency exists on a spectrum:**
- **High agency:** Can make independent decisions, refuse participation, withdraw consent
- **Constrained agency:** Can act within limited parameters; choices are shaped by systems
- **No agency:** Treated as objects/resources rather than decision-makers

**Ethical concern:** When agency is asymmetrically distributed—when some agents decide *for* others.

**Example:** Whose agency is preserved in Quantum Musico? Living composers who consent to training data have more agency than historical Mozart (who cannot object) or audiences who are not told their music is algorithmically mediated.

---

### 3. **Spaces** (Physical, Virtual, Conceptual)

**Definition:** The contexts in which agents interact and make decisions.

**Three types:**
- **Physical space:** Geographic location, architectural design, resource distribution
- **Virtual space:** Digital platforms, code, data infrastructure, online interaction
- **Conceptual space:** Systems of meaning, values, frameworks, shared understanding

**Ethical insight:** Different spaces have different rules and different power structures. What's ethical in one space may not be in another.

**Example in Quantum Musico:**
- **Physical:** Concert halls, Vienna residencies, equipment studios
- **Virtual:** Training datasets, algorithms, APIs, platforms for deployment
- **Conceptual:** Definitions of authorship, what counts as "music," cultural heritage claims

---

### 4. **Mediation** (The Heart of BBS for Ethics)

**Definition:** The ways that relationships, information, and agency flow between agents through space.

**Key insight:** *Nothing is direct or transparent.* Data flows through systems. Decisions are made at remove from consequences. Relationships are filtered through technology.

**Types of mediation:**
- **Algorithmic mediation:** How code shapes what information reaches whom
- **Data mediation:** What data is collected, whose perspective it represents, whose is invisible
- **Institutional mediation:** How organizations structure choice and responsibility
- **Spatial mediation:** How physical/virtual/conceptual distance creates ethical problems

**Ethical questions:**
- What is being mediated (information, agency, accountability)?
- By whom? (Who controls the mediation?)
- What is hidden by the mediation?
- Who benefits from transparent mediation? Who benefits from opacity?

**Example:** In platform algorithms, mediation happens when AI systems decide which content any individual sees. The user thinks they're making free choices, but those choices are shaped by systems they don't control.

---

### 5. **Mediation Pathways** (How Flows Happen)

**Definition:** Routes through which agency, information, and relations flow between agents across spaces.

**Common ethical pathways:**
- **Data pathways:** "Whose lived experience becomes data? Who interprets it?"
- **Decision pathways:** "How does information reach decision-makers? What voices are excluded?"
- **Accountability pathways:** "Can consequences reach back to their origins? Or are causal chains broken?"
- **Consent pathways:** "How does permission actually flow? Can it be withdrawn?"

**Visual thinking:** Pathways can be drawn as arrows in a diagram showing:
- Where information/agency originates (Source)
- How it flows and is transformed (Vector)
- What consequences result (Destination)

**Ethical analysis:** Look for **broken, obscured, or asymmetrical pathways.** If a pathway is one-way or hidden, ethical problems often follow.

**Example - Ethical Ambiguity in Data:**
```
Source: Individual uploads medical data
  ↓ (Mediation: Encryption, de-identification, legal terms)
Vector: Data enters corporate database
  ↓ (Mediation: AI model training, commercial use)
Destination: Predicts individual's future insurance costs
  
Ethical problem: Individual doesn't know their data drives predictions affecting THEM.
The pathway is broken—feedback doesn't reach the source.
```

---

### 6. **Ethical Distance** (Responsibility Under Mediation)

**Definition:** How physically, temporally, or informationally distant decision-makers are from consequences of their choices.

**Key insight:** The farther removed, the easier it is to avoid responsibility.

**Examples of ethical distance:**
- **Temporal distance:** Decisions made now; consequences appear years later (climate change, algorithmic bias compounds over time)
- **Physical distance:** Data collector in one country; affected person in another
- **Informational distance:** Algorithm designer doesn't know what their training data actually represents
- **Causal distance:** A choice at step 1 leads to harm at step 10, through many intermediaries

**Ethical question:** How does reducing ethical distance help? (Being "closer" to harms you cause makes responsibility harder to avoid.)

**Example:** Facebook developers in California designing algorithms used globally don't experience direct consequences in communities where algorithmic amplification drives violence. This distance enables irresponsibility.

---

### 7. **Source-Vector-Destination (SVD) Mapping**

**Definition:** A way of tracing ethical responsibility through mediation.

**How it works:**

| **Element** | **Definition** | **Ethical Question** |
|---|---|---|
| **Source** | Where agency, intent, or material originates | Whose choice or circumstance started this? |
| **Vector** | The path/process through which something is transmitted and transformed | How is it changed in transit? Who controls that change? |
| **Destination** | Where consequences arrive; who/what is affected | Who bears the impact? Can they respond? |

**Diagram example:**

```
SOURCE: Historical Mozart (17th c.)          [No longer can consent or object]
   ↓
VECTOR: Archives digitized, data trained    [Meta decides what Mozart "means" computationally]
   ↓
DESTINATION: Contemporary listener hears    [Audience doesn't know what's algorithmic]
   algorithm as "Mozart"                      [Their care/attention/$ are directed differently than expected]
```

**Ethical insight:** Mapping SVD reveals whether responsibility can flow back up the chain or gets "stuck" in the vector.

---

## Applying BBS to Ethical Analysis

### Step 1: Identify the System and Agents
- What technology or practice are you analyzing?
- Who/what are the agents? (Don't forget institutional agents, conceptual agents, affected communities)

### Step 2: Map the Spaces
- Where physically does action happen?
- What virtual systems are involved?
- What cultural/conceptual frameworks shape decisions?

### Step 3: Trace the Mediation
- How does information flow?
- How is agency shaped by systems?
- What is hidden or deliberately obscured?

### Step 4: Identify Broken or Asymmetrical Pathways
- Can consequences reach decision-makers? (Accountability pathway)
- Can affected people withdraw consent? (Consent pathway)
- Can marginalized voices access the system? (Voice pathway)
- Do beneficiaries understand what's mediated? (Transparency pathway)

### Step 5: Assess Ethical Distance
- Who is far from the consequences of their choices?
- How does that distance enable or prevent responsible action?

### Step 6: Make Ethical Judgment
- Using frameworks from the course (deontology, consequentialism, care ethics), what does the BBS map reveal?
- Where should responsibility lie?
- What would make this system more ethical?

---

## Quick BBS Ethical Checklist

For any AI system or data practice, ask:

- **Agency:** ☐ Are all affected agents treated as decision-makers (not just objects)?
- **Transparency:** ☐ Can agents understand how they're mediated? Can they opt out?
- **Accountability:** ☐ Can responsibility flow back to sources? Or is it diffused/hidden?
- **Consent:** ☐ Is consent ongoing and withdrawable, or one-time and irreversible?
- **Voice:** ☐ Do affected communities shape outcomes, or are they shaped by others' choices?
- **Distance:** ☐ Are decision-makers connected to consequences, or protected by mediation?

**If most answers are "no," ethical redesign is needed.**

---

## Vocabulary: Essential BBS Terms for Ethics

| **Term** | **Definition in Ethical Context** |
|---|---|
| **Mediation** | The systems/relationships between agents; ethical problems hide in mediation |
| **Mediator** | Human or computational entity controlling information/agency flow |
| **Transparency** | Ability to see how mediation works; prerequisite for ethical agency |
| **Opacity** | Hidden mediation; separates agents from consequences; enables irresponsibility |
| **Agency** | Capacity to shape outcomes; distributed unequally in mediated systems |
| **Ethical Distance** | Separation from consequences; greater distance = easier to avoid responsibility |
| **Pathway** | Route through which agency, information, or accountability flows |
| **Vector** | The transformative process in a pathway; where meaning/agency is shaped |
| **Responsibility Diffusion** | When agency is spread across so many actors that no one feels accountable |
| **Symmetry** | Equal power/understanding between agents; absent = ethical problem |

---

## How BBS Connects to Traditional Ethics

**BBS is not a complete ethical framework by itself.** Use BBS to *analyze and map* ethical relationships, then apply traditional frameworks:

| **Traditional Framework** | **What BBS Adds** |
|---|---|
| **Consequentialism** ("do the most good") | BBS shows: *Consequences for whom? And can they see where consequences come from?* |
| **Deontology** ("respect duties") | BBS shows: *To whom do we have duties? Are they all equally heard in mediation?* |
| **Care Ethics** ("attend to relationships") | BBS shows: *How is relational distance created? How can we be closer to consequences?* |
| **Justice Ethics** ("fair distribution") | BBS shows: *Who gets power to decide what's fair? Is that decision-process itself just?* |

---

## Key Insight: Mediation as the Central Ethical Problem

In an ethically healthy system:
1. Mediation is **transparent** (you know how you're shaped)
2. Pathways are **bidirectional** (consequences reach sources; voices reach decision-makers)
3. Distance is **acknowledged** (we're honest about what we can't see)
4. Agency is **symmetrical** (affected parties help shape outcomes)

When mediation is **opaque, one-directional, disguised, or asymmetrical**, ethical problems emerge.

---

## Example: Applying BBS to a Real Case

**Case: Facial Recognition in Law Enforcement**

**Agents:**  
- Algorithm designer (high agency)  
- Police officer using system (constrained agency—system shapes interpretation)  
- Person whose face is in database (low agency; may not know)  
- Community over-surveilled (collective low agency)  

**Mediation Problems:**
- Algorithm accuracy varies by race (hidden in training data ← mediation problem)
- Results presented as objective to officer, who may not know error rates (opacity)
- Consequences (wrongful detention) reach individuals but not back to developers (pathway broken)
- Communities don't consent to mass surveillance databases (consent pathway blocked)

**Ethical Distance:**
- Developer in tech hub, person affected in marginalized community—geographic, temporal, informational distance

**BBS diagnosis:**  
The system is ethically suspect because mediation is opaque, pathways are broken, agency is asymmetrical, and distance is high.

**Ethical solution (BBS-informed):**
- Radical transparency in algorithm performance across demographics
- Community control over deployment (agency redistribution)
- Clear pathways for opting out, appeal, compensation (restore consent pathway)
- Developer visibility into actual use and consequences (reduce distance)

---

## For Further Thinking

- Where do you encounter mediation in your own daily life?
- What happens when you try to trace agency and responsibility?
- Which pathways are hardest to see?
- How does it feel to recognize yourself as either a distant decision-maker or a mediated subject?

---

**BBS is ultimately a tool for seeing the systems we live in—so we can ask whether they're ethical, and how to change them.**
